---
title: ONNX
emoji: ğŸ“‰
colorFrom: blue
colorTo: pink
sdk: docker
pinned: false
license: mit
short_description: deploying ML model in flask
---


## ğŸŒ¸ Iris Flower Classifier (Flask + ONNX)

This project is a simple Flask web application that predicts the species of an Iris flower based on its measurements using a pre-trained **Logistic Regression model**. The model is exported in **ONNX (Open Neural Network Exchange)** format, allowing for efficient, framework-independent inference.

---

### ğŸš€ Live Demo

> ğŸ“Œ Enter sepal length, sepal width, petal length, and petal width
> ğŸ“Œ Get predicted Iris species: *Setosa*, *Versicolor*, or *Virginica*

---

### ğŸ“ Project Structure

```
.
â”œâ”€â”€ app.py                  # Flask web app
â”œâ”€â”€ iris_model.onnx         # ONNX-trained model
â”œâ”€â”€ Dockerfile              # Dockerfile For HuggingFace   
â”œâ”€â”€ class_labels.json       # Class label mapping
â”œâ”€â”€ requirements.txt        # Required Python packages
â””â”€â”€ templates/
    â””â”€â”€ index.html          # HTML form for input
```

---

### ğŸ’¡ Features

* ğŸ§  Trained with `scikit-learn` Logistic Regression
* ğŸ”„ Converted to ONNX for optimized runtime inference
* ğŸŒ Deployed with Flask and HTML frontend
* ğŸª„ Clean input form with real-time result display

---

### ğŸ“¦ Setup Instructions

1. **Clone the Repository**

   ```bash
   git clone https://github.com/lovnishverma/iris-onnx-flask.git
   cd iris-onnx-flask
   ```

2. **Install Dependencies**

   ```bash
   pip install -r requirements.txt
   ```

3. **Run the Flask App**

   ```bash
   python app.py
   ```

4. **Open in Browser**

   ```
   http://127.0.0.1:5000
   ```

---

### ğŸ§ª Test Example

Try the following values:

```text
Sepal Length: 5.7
Sepal Width: 3.2
Petal Length: 5.2
Petal Width: 1.9
```

Output:

```
Predicted Flower Type: virginica
```

---

### ğŸ¤– Why ONNX instead of Pickle or Joblib?

| Feature             | Pickle/Joblib                          | ONNX                                            |
| ------------------- | -------------------------------------- | ----------------------------------------------- |
| ğŸ”’ Security         | Unsafe for web apps (can execute code) | Safer (no code execution risk)                  |
| ğŸ”„ Interoperability | Python only                            | Works across platforms/languages                |
| âš¡ Speed             | OK in Python                           | Faster inference (especially with ONNX Runtime) |
| â˜ï¸ Deployment       | Limited                                | Ideal for production, Docker, or cloud          |
| ğŸ“¦ Size & Format    | Python-specific                        | Efficient binary format, language-independent   |

> âœ… **ONNX** is preferred when deploying machine learning models in production or cross-platform environments.

---

### ğŸ“š Requirements

```txt
flask
onnxruntime
numpy
gunicorn
```

---

### ğŸ“œ License

This project is licensed under the [MIT License](LICENSE).

---

### ğŸ™‹â€â™‚ï¸ Author

Made with â¤ï¸ by [Lovnish Verma](https://lovnishverma.github.io)

---
